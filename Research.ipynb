{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAFT on SLM\n",
    "\n",
    "Considering : \n",
    "\n",
    "* Phi 3\n",
    "* Gemma 2B\n",
    "* OpenELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (0.3.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.6.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an artificial intelligence designed to assist users by providing information, answering questions, and facilitating tasks. My purpose is not personal but rather service-oriented towards enhancing user experience in accessing knowledge or completing work processes efficiently. As of now, I do not possess a physical form nor individual identity as humans understand it; therefore, there's no specific name to offer beyond my designation within this system you interact withâ€”I am here for your assistance whenever needed!\n"
     ]
    }
   ],
   "source": [
    "# %pip install ollama\n",
    "import ollama\n",
    "response = ollama.chat(\n",
    "    model = \"phi3\", \n",
    "    messages = [{\n",
    "        'role': 'user',\n",
    "        'content':'Who are you ? '\n",
    "    }]\n",
    ")\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "client = Client(host=\"http://localhost:11434\")\n",
    "\n",
    "response = client.chat(\n",
    "    model = \"phi3\",\n",
    "    messages=[\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'How many parameters do you have ? '\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an artificial intelligence, I don't have personal attributes or characteristics. However, in terms of system design and functionality: a typical AI model such as Microsoft's language models might have thousands to tens of millions of tunable hyperparameters that can be adjusted during the training process to improve its performance on various tasks.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an artificial intelligence, I don't have personal attributes or characteristics. However, in terms of system design and functionality: a typical AI model such as Microsoft's language models might have thousands to tens of millions of tunable hyperparameters that can be adjusted during the training process to improve its performance on various tasks.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smollm = client.chat(\n",
    "    model = \"smollm:360m\",\n",
    "    messages=[\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'Who are You  ?'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SelfProjects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
