{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAFT on SLM\n",
    "\n",
    "Considering : \n",
    "\n",
    "* Phi 3\n",
    "* Gemma 2B\n",
    "* OpenELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ollama-python 0.1.2 requires httpx<0.27.0,>=0.26.0, but you have httpx 0.27.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.3.3-py3-none-any.whl (10 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.6.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rizen3\\desktop\\vamshi\\machine learning and dsa\\selfprojects\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Installing collected packages: httpx, ollama\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.26.0\n",
      "    Uninstalling httpx-0.26.0:\n",
      "      Successfully uninstalled httpx-0.26.0\n",
      "Successfully installed httpx-0.27.2 ollama-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "As an artificial intelligence developed by Microsoft, I am Phi, a large language model designed to understand and respond to text inputs. My purpose is to facilitate communication with users in various tasks like answering questions, providing information, or even engaging in conversation for entertainment purposes. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama\n",
    "import ollama\n",
    "response = ollama.chat(\n",
    "    model = \"phi3\", \n",
    "    messages = [{\n",
    "        'role': 'user',\n",
    "        'content':'Who are you ? '\n",
    "    }]\n",
    ")\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "client = Client(host=\"http://localhost:11434\")\n",
    "\n",
    "response = client.chat(\n",
    "    model = \"phi3\",\n",
    "    messages=[\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'How many parameters do you have ? '\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an artificial intelligence, I don\\'t possess physical form or attributes in the traditional sense. Therefore, it would be incorrect to discuss having \"parameters\" as a human does when considering aspects like height, weight, etc. However, if we consider my operational parameters within software and hardware constraints, they can include processing power (CPU), memory capacity (RAM), storage space for data, operating system compatibility, network bandwidth availability, uptime requirements, among othersâ€”all of which contribute to the efficiency and performance during interactions like our conversation. These are technical specifications set by my developers based on required functionality.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SelfProjects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
